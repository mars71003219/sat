# ìœ„ì„± í…”ë ˆë©”íŠ¸ë¦¬ ë¶„ì„ ì‹œìŠ¤í…œ - ì‚¬ìš©ì ë§¤ë‰´ì–¼

## ëª©ì°¨

1. [ì‹œìŠ¤í…œ ì‹œì‘ ë° ì¢…ë£Œ](#1-ì‹œìŠ¤í…œ-ì‹œì‘-ë°-ì¢…ë£Œ)
2. [ë©”ì‹œì§€ í ìƒíƒœ í™•ì¸](#2-ë©”ì‹œì§€-í-ìƒíƒœ-í™•ì¸)
3. [ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸](#3-ë°ì´í„°ë² ì´ìŠ¤-í™•ì¸)
4. [ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§](#4-ì‹œìŠ¤í…œ-ëª¨ë‹ˆí„°ë§)
5. [ì¶”ë¡  ì‘ì—… ì‹¤í–‰](#5-ì¶”ë¡ -ì‘ì—…-ì‹¤í–‰)
6. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#6-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)
7. [ì„±ëŠ¥ íŠœë‹](#7-ì„±ëŠ¥-íŠœë‹)

---

## 1. ì‹œìŠ¤í…œ ì‹œì‘ ë° ì¢…ë£Œ

### 1.1 ì´ˆê¸° ì„¤ì •

**Kafka í´ëŸ¬ìŠ¤í„° ID ìƒì„±** (ìµœì´ˆ 1íšŒë§Œ):

```bash
cd /mnt/c/projects/satellite
./init-kafka.sh
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” `.env` íŒŒì¼ì— `KAFKA_CLUSTER_ID`ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

### 1.2 ì „ì²´ ì‹œìŠ¤í…œ ì‹œì‘

```bash
docker compose up -d
```

**ì‹œì‘ ìˆœì„œ**:
1. ì¸í”„ë¼ ì„œë¹„ìŠ¤ (Kafka, RabbitMQ, PostgreSQL)
2. AI ì„œë¹„ìŠ¤ (Triton Server)
3. ì• í”Œë¦¬ì¼€ì´ì…˜ ì„œë¹„ìŠ¤ (Operation Server, Analysis Worker)
4. ì›¹ ì„œë¹„ìŠ¤ (Frontend, Nginx)

**ì‹œì‘ ì‹œê°„**: ì•½ 30-60ì´ˆ (Triton Server GPU ì´ˆê¸°í™” í¬í•¨)

### 1.3 ê°œë³„ ì„œë¹„ìŠ¤ ì‹œì‘

```bash
# íŠ¹ì • ì„œë¹„ìŠ¤ë§Œ ì‹œì‘
docker compose up -d <service_name>

# ì˜ˆì‹œ
docker compose up -d operation-server
docker compose up -d analysis-worker-1
```

### 1.4 ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸

```bash
# ëª¨ë“  ì„œë¹„ìŠ¤ ìƒíƒœ
docker compose ps

# íŠ¹ì • ì„œë¹„ìŠ¤ ìƒíƒœ
docker compose ps operation-server
```

**ì •ìƒ ìƒíƒœ ì˜ˆì‹œ**:
```
NAME                   STATUS         PORTS
kafka                  Up 5 minutes   0.0.0.0:9092->9092/tcp
rabbitmq               Up 5 minutes   0.0.0.0:5672->5672/tcp, 0.0.0.0:15672->15672/tcp
postgres               Up 5 minutes   0.0.0.0:5432->5432/tcp
triton-server          Up 5 minutes (healthy)   0.0.0.0:8500-8502->8000-8002/tcp
analysis-worker-1      Up 5 minutes
operation-server       Up 5 minutes   0.0.0.0:8000->8000/tcp
```

### 1.5 ì‹œìŠ¤í…œ ì¢…ë£Œ

**ì „ì²´ ì‹œìŠ¤í…œ ì¢…ë£Œ**:
```bash
docker compose down
```

**ë°ì´í„° ìœ ì§€í•˜ë©° ì¢…ë£Œ**:
```bash
docker compose down
# ë³¼ë¥¨ì€ ìœ ì§€ë¨ (postgres_data, kafka_data, etc.)
```

**ë°ì´í„° í¬í•¨ ì™„ì „ ì‚­ì œ**:
```bash
docker compose down -v
# ì£¼ì˜: ëª¨ë“  ë°ì´í„°ê°€ ì‚­ì œë©ë‹ˆë‹¤!
```

### 1.6 ë¡œê·¸ í™•ì¸

```bash
# ì „ì²´ ë¡œê·¸
docker compose logs

# íŠ¹ì • ì„œë¹„ìŠ¤ ë¡œê·¸
docker compose logs operation-server

# ì‹¤ì‹œê°„ ë¡œê·¸ (follow)
docker compose logs -f analysis-worker-1

# ìµœê·¼ Nê°œ ë¼ì¸ë§Œ
docker compose logs --tail 50 kafka-inference-trigger
```

---

## 2. ë©”ì‹œì§€ í ìƒíƒœ í™•ì¸

### 2.1 Kafka ìƒíƒœ í™•ì¸

#### 2.1.1 Kafka UI (ì›¹ ì¸í„°í˜ì´ìŠ¤)

**ì ‘ì†**: http://localhost:8080

**ì£¼ìš” ê¸°ëŠ¥**:
- í† í”½ ëª©ë¡ ë° ìƒì„¸ ì •ë³´
- ë©”ì‹œì§€ ì‹¤ì‹œê°„ í™•ì¸
- Consumer Group ìƒíƒœ
- Broker ìƒíƒœ

**í™•ì¸ ì‚¬í•­**:

1. **Topics**:
   ```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Topic: satellite-telemetry          â”‚
   â”‚ Partitions: 1                       â”‚
   â”‚ Replication Factor: 1               â”‚
   â”‚ Messages: 1,234                     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   ```

2. **Consumer Groups**:
   ```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Group: analysis-inference-group     â”‚
   â”‚ State: Stable                       â”‚
   â”‚ Members: 1                          â”‚
   â”‚ Lag: 0                              â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   ```

#### 2.1.2 CLIë¡œ Kafka í™•ì¸

**í† í”½ ëª©ë¡**:
```bash
docker exec kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --list
```

**í† í”½ ìƒì„¸ ì •ë³´**:
```bash
docker exec kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --describe \
  --topic satellite-telemetry
```

**Consumer Group ìƒíƒœ**:
```bash
docker exec kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe \
  --group analysis-inference-group
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
GROUP                       TOPIC                PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG
analysis-inference-group    satellite-telemetry  0          1234           1234            0
```

**ì¤‘ìš” ì§€í‘œ**:
- `LAG = 0`: ëª¨ë“  ë©”ì‹œì§€ê°€ ì²˜ë¦¬ë¨ âœ…
- `LAG > 0`: ì²˜ë¦¬ ëŒ€ê¸° ì¤‘ì¸ ë©”ì‹œì§€ ì¡´ì¬ âš ï¸
- `LAG > 1000`: ì²˜ë¦¬ ì§€ì—° ë°œìƒ âŒ

**ë©”ì‹œì§€ ì†Œë¹„ í™•ì¸**:
```bash
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic satellite-telemetry \
  --from-beginning \
  --max-messages 5
```

### 2.2 RabbitMQ ìƒíƒœ í™•ì¸

#### 2.2.1 RabbitMQ Management UI

**ì ‘ì†**: http://localhost:15672

**ë¡œê·¸ì¸**:
- Username: `guest`
- Password: `guest`

**ì£¼ìš” íƒ­**:

1. **Overview**:
   - ì „ì²´ ë©”ì‹œì§€ rate
   - í ìƒíƒœ
   - ì—°ê²° ìˆ˜

2. **Connections**:
   ```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Client: operation-server                â”‚
   â”‚ State: running                          â”‚
   â”‚ Channels: 1                             â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Client: analysis-worker-1               â”‚
   â”‚ State: running                          â”‚
   â”‚ Channels: 2                             â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   ```

3. **Queues**:
   ```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Queue: inference                        â”‚
   â”‚ Ready: 0                                â”‚
   â”‚ Unacked: 2                              â”‚
   â”‚ Total: 2                                â”‚
   â”‚ Incoming: 5.2/s                         â”‚
   â”‚ Deliver / Get: 5.2/s                    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   ```

**ì •ìƒ ìƒíƒœ ì§€í‘œ**:
- `Ready: 0~10`: ì •ìƒ âœ…
- `Ready: > 100`: ì²˜ë¦¬ ì§€ì—° âš ï¸
- `Unacked`: Workerê°€ ì²˜ë¦¬ ì¤‘ì¸ ë©”ì‹œì§€
- `Incoming â‰ˆ Deliver`: ê· í˜• ì¡íŒ ì²˜ë¦¬ âœ…

#### 2.2.2 CLIë¡œ RabbitMQ í™•ì¸

**í ëª©ë¡**:
```bash
docker exec rabbitmq rabbitmqctl list_queues
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
Timeout: 60.0 seconds ...
Listing queues for vhost / ...
name            messages
celery          0
inference       2
```

**ì—°ê²° ëª©ë¡**:
```bash
docker exec rabbitmq rabbitmqctl list_connections
```

**Consumer ëª©ë¡**:
```bash
docker exec rabbitmq rabbitmqctl list_consumers
```

### 2.3 Celery ì‘ì—… ëª¨ë‹ˆí„°ë§

#### 2.3.1 Flower (ì›¹ ì¸í„°í˜ì´ìŠ¤)

**ì ‘ì†**: http://localhost:5555

**ì£¼ìš” ê¸°ëŠ¥**:

1. **Workers** íƒ­:
   ```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Worker: analysis-worker-1                       â”‚
   â”‚ Status: Online                                  â”‚
   â”‚ Active: 2 tasks                                 â”‚
   â”‚ Processed: 1,234 tasks                          â”‚
   â”‚ Failed: 5 tasks                                 â”‚
   â”‚ Succeeded: 1,229 tasks                          â”‚
   â”‚ Retried: 3 tasks                                â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   ```

2. **Tasks** íƒ­:
   - ì‹¤ì‹œê°„ ì‘ì—… ëª©ë¡
   - ì‘ì—… ìƒíƒœ (PENDING, STARTED, SUCCESS, FAILURE)
   - ì‘ì—… ì‹¤í–‰ ì‹œê°„

3. **Monitor** íƒ­:
   - ì‹¤ì‹œê°„ ê·¸ë˜í”„
   - ì²˜ë¦¬ëŸ‰ (tasks/sec)
   - ì„±ê³µ/ì‹¤íŒ¨ ë¹„ìœ¨

**ì •ìƒ ìƒíƒœ ì§€í‘œ**:
- Success Rate: > 95% âœ…
- Active Tasks: 0-4 (concurrency=2ì´ë¯€ë¡œ) âœ…
- Failed Tasks: < 5% âš ï¸

#### 2.3.2 CLIë¡œ Celery í™•ì¸

**Worker ìƒíƒœ**:
```bash
docker exec analysis-worker-1 celery -A tasks inspect active
```

**ë“±ë¡ëœ Task ëª©ë¡**:
```bash
docker exec analysis-worker-1 celery -A tasks inspect registered
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```json
{
  "celery@analysis-worker-1": [
    "analysis_server.tasks.run_inference",
    "analysis_server.tasks.run_subsystem_inference"
  ]
}
```

**Worker í†µê³„**:
```bash
docker exec analysis-worker-1 celery -A tasks inspect stats
```

---

## 3. ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸

### 3.1 PostgreSQL ì ‘ì†

#### 3.1.1 psql CLI ì ‘ì†

```bash
docker exec -it postgres psql -U admin -d orders_db
```

**í”„ë¡¬í”„íŠ¸**: `orders_db=#`

#### 3.1.2 ì£¼ìš” ì¿¼ë¦¬

**í…Œì´ë¸” ëª©ë¡**:
```sql
\dt
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
                 List of relations
 Schema |          Name           | Type  | Owner
--------+-------------------------+-------+-------
 public | inference_jobs          | table | admin
 public | subsystem_inferences    | table | admin
 public | inference_results       | table | admin
```

**í…Œì´ë¸” êµ¬ì¡° í™•ì¸**:
```sql
\d inference_jobs
\d subsystem_inferences
```

### 3.2 ì¶”ë¡  ê²°ê³¼ ì¡°íšŒ

#### 3.2.1 ìµœê·¼ ì‘ì—… ì¡°íšŒ

```sql
-- ìµœê·¼ 10ê°œ ì‘ì—…
SELECT job_id, satellite_id, source, status, created_at, completed_at
FROM inference_jobs
ORDER BY created_at DESC
LIMIT 10;
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
         job_id              | satellite_id |      source        |  status   |       created_at        |      completed_at
-----------------------------+--------------+--------------------+-----------+-------------------------+-------------------------
 COMPLETE-TEST-1761802301    | SAT-001      | manual             | completed | 2025-10-30 12:34:56.789 | 2025-10-30 12:35:01.234
 kafka-SAT-002-1761802245    | SAT-002      | kafka_auto_trigger | completed | 2025-10-30 12:33:00.123 | 2025-10-30 12:33:05.456
```

#### 3.2.2 ì„œë¸Œì‹œìŠ¤í…œë³„ ê²°ê³¼ ì¡°íšŒ

```sql
-- íŠ¹ì • Jobì˜ ëª¨ë“  ì„œë¸Œì‹œìŠ¤í…œ ê²°ê³¼
SELECT job_id, subsystem, model_name, status, anomaly_detected, anomaly_score
FROM subsystem_inferences
WHERE job_id = 'COMPLETE-TEST-1761802301'
ORDER BY subsystem;
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
         job_id              | subsystem |   model_name    |  status   | anomaly_detected | anomaly_score
-----------------------------+-----------+-----------------+-----------+------------------+---------------
 COMPLETE-TEST-1761802301    | aocs      | lstm_timeseries | completed | f                |        0.6120
 COMPLETE-TEST-1761802301    | comm      | lstm_timeseries | completed | f                |        0.1970
 COMPLETE-TEST-1761802301    | eps       | lstm_timeseries | completed | f                |        0.2500
 COMPLETE-TEST-1761802301    | thermal   | lstm_timeseries | completed | f                |        0.0480
```

#### 3.2.3 ì´ìƒ ê°ì§€ ê²°ê³¼ ì¡°íšŒ

```sql
-- ì´ìƒì´ ê°ì§€ëœ ëª¨ë“  ì„œë¸Œì‹œìŠ¤í…œ
SELECT * FROM v_anomaly_alerts
ORDER BY created_at DESC
LIMIT 10;
```

```sql
-- íŠ¹ì • ìœ„ì„±ì˜ ì´ìƒ ê°ì§€ ì´ë ¥
SELECT satellite_id, subsystem, anomaly_score, created_at
FROM v_anomaly_alerts
WHERE satellite_id = 'SAT-001'
ORDER BY created_at DESC;
```

#### 3.2.4 ì‘ì—… ìš”ì•½ ì¡°íšŒ

```sql
-- ì‘ì—… ìš”ì•½ ë·° ì‚¬ìš©
SELECT * FROM v_inference_job_summary
WHERE job_id = 'COMPLETE-TEST-1761802301';
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
         job_id              | satellite_id | source | trigger_reason | job_status |       created_at        | total_subsystems | completed_subsystems | total_time_seconds | inference_count | anomalies_detected | avg_inference_time_ms |      subsystem_results
-----------------------------+--------------+--------+----------------+------------+-------------------------+------------------+----------------------+--------------------+-----------------+--------------------+-----------------------+----------------------------
 COMPLETE-TEST-1761802301    | SAT-001      | manual | manual_test    | completed  | 2025-10-30 12:34:56.789 |                4 |                    4 |              4.445 |               4 |                  0 |                125.50 | [{"subsystem":"aocs",...}]
```

### 3.3 í†µê³„ ë° ë¶„ì„ ì¿¼ë¦¬

#### 3.3.1 ì „ì²´ í†µê³„

```sql
-- ì „ì²´ ì‘ì—… í†µê³„
SELECT
    COUNT(*) as total_jobs,
    COUNT(CASE WHEN status = 'completed' THEN 1 END) as completed,
    COUNT(CASE WHEN status = 'failed' THEN 1 END) as failed,
    COUNT(CASE WHEN status = 'processing' THEN 1 END) as processing,
    ROUND(100.0 * COUNT(CASE WHEN status = 'completed' THEN 1 END) / COUNT(*), 2) as success_rate
FROM inference_jobs;
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
 total_jobs | completed | failed | processing | success_rate
------------+-----------+--------+------------+--------------
       1250 |      1180 |     65 |          5 |        94.40
```

#### 3.3.2 ì„œë¸Œì‹œìŠ¤í…œë³„ í†µê³„

```sql
-- ì„œë¸Œì‹œìŠ¤í…œë³„ ì´ìƒ ê°ì§€ìœ¨
SELECT
    subsystem,
    COUNT(*) as total,
    COUNT(CASE WHEN anomaly_detected THEN 1 END) as anomalies,
    ROUND(100.0 * COUNT(CASE WHEN anomaly_detected THEN 1 END) / COUNT(*), 2) as anomaly_rate,
    ROUND(AVG(anomaly_score)::numeric, 4) as avg_score
FROM subsystem_inferences
WHERE status = 'completed'
GROUP BY subsystem
ORDER BY anomaly_rate DESC;
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
 subsystem | total | anomalies | anomaly_rate | avg_score
-----------+-------+-----------+--------------+-----------
 eps       |   312 |        15 |         4.81 |    0.3245
 thermal   |   312 |         8 |         2.56 |    0.1890
 aocs      |   312 |         5 |         1.60 |    0.4512
 comm      |   312 |         3 |         0.96 |    0.2134
```

#### 3.3.3 ì‹œê°„ëŒ€ë³„ ì²˜ë¦¬ëŸ‰

```sql
-- ìµœê·¼ 24ì‹œê°„ ì‹œê°„ëŒ€ë³„ ì²˜ë¦¬ëŸ‰
SELECT
    DATE_TRUNC('hour', created_at) as hour,
    COUNT(*) as jobs,
    AVG(EXTRACT(EPOCH FROM (completed_at - created_at))) as avg_time_sec
FROM inference_jobs
WHERE created_at > NOW() - INTERVAL '24 hours'
    AND status = 'completed'
GROUP BY DATE_TRUNC('hour', created_at)
ORDER BY hour DESC;
```

#### 3.3.4 ëª¨ë¸ë³„ ì„±ëŠ¥

```sql
-- ëª¨ë¸ë³„ í‰ê·  ì¶”ë¡  ì‹œê°„
SELECT
    model_name,
    COUNT(*) as total,
    ROUND(AVG(inference_time_ms)::numeric, 2) as avg_time_ms,
    ROUND(MIN(inference_time_ms)::numeric, 2) as min_time_ms,
    ROUND(MAX(inference_time_ms)::numeric, 2) as max_time_ms
FROM subsystem_inferences
WHERE status = 'completed'
GROUP BY model_name;
```

### 3.4 ë°ì´í„° ì •ë¦¬

#### 3.4.1 ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ

```sql
-- 30ì¼ ì´ìƒ ëœ completed ì‘ì—… ì‚­ì œ
DELETE FROM inference_jobs
WHERE status = 'completed'
  AND completed_at < NOW() - INTERVAL '30 days';
```

#### 3.4.2 ì‹¤íŒ¨í•œ ì‘ì—… ì •ë¦¬

```sql
-- ì‹¤íŒ¨í•œ ì‘ì—…ë§Œ ì¡°íšŒ
SELECT job_id, satellite_id, error_message, created_at
FROM inference_jobs
WHERE status = 'failed'
ORDER BY created_at DESC;
```

```sql
-- 7ì¼ ì´ìƒ ëœ ì‹¤íŒ¨ ì‘ì—… ì‚­ì œ
DELETE FROM inference_jobs
WHERE status = 'failed'
  AND created_at < NOW() - INTERVAL '7 days';
```

#### 3.4.3 í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚­ì œ

```sql
-- í…ŒìŠ¤íŠ¸ ì‘ì—…ë§Œ ì‚­ì œ
DELETE FROM inference_jobs
WHERE source = 'test' OR job_id LIKE '%TEST%';
```

### 3.5 ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…

```bash
# ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
docker exec postgres pg_dump -U admin orders_db > backup_$(date +%Y%m%d_%H%M%S).sql

# íŠ¹ì • í…Œì´ë¸”ë§Œ ë°±ì—…
docker exec postgres pg_dump -U admin -t inference_jobs orders_db > inference_jobs_backup.sql
```

### 3.6 ë°ì´í„°ë² ì´ìŠ¤ ë³µì›

```bash
# ë°±ì—… ë³µì›
cat backup_20251030_123456.sql | docker exec -i postgres psql -U admin orders_db
```

---

## 4. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§

### 4.1 VictoriaMetrics ëª¨ë‹ˆí„°ë§

**ì ‘ì†**: http://localhost:8428

#### 4.1.1 ë©”íŠ¸ë¦­ ì¡°íšŒ (PromQL)

**ë¸Œë¼ìš°ì €ì—ì„œ**:
```
http://localhost:8428/vmui
```

**ì£¼ìš” ë©”íŠ¸ë¦­**:

1. **ë°°í„°ë¦¬ ì „ì••**:
   ```promql
   satellite_battery_voltage{satellite_id="SAT-001"}
   ```

2. **ì˜¨ë„**:
   ```promql
   satellite_temperature{satellite_id="SAT-001"}
   ```

3. **ì „ë ¥ ì†Œë¹„**:
   ```promql
   satellite_power_consumption{satellite_id="SAT-001"}
   ```

#### 4.1.2 CLIë¡œ ë©”íŠ¸ë¦­ ì¡°íšŒ

```bash
# ìµœì‹  ê°’ ì¡°íšŒ
curl 'http://localhost:8428/api/v1/query?query=satellite_temperature{satellite_id="SAT-001"}'

# ì‹œê°„ ë²”ìœ„ ì¡°íšŒ
curl 'http://localhost:8428/api/v1/query_range?query=satellite_temperature{satellite_id="SAT-001"}&start=2025-10-30T00:00:00Z&end=2025-10-30T23:59:59Z&step=1m'
```

### 4.2 Triton Server ëª¨ë‹ˆí„°ë§

#### 4.2.1 Health Check

```bash
# HTTP Health Check
curl http://localhost:8500/v2/health/ready

# ì •ìƒ ì‘ë‹µ: 200 OK (ë¹ˆ ì‘ë‹µ ë˜ëŠ” {})
```

#### 4.2.2 ëª¨ë¸ ìƒíƒœ

```bash
# ëª¨ë“  ëª¨ë¸ ëª©ë¡
curl http://localhost:8500/v2/models

# íŠ¹ì • ëª¨ë¸ ìƒíƒœ
curl http://localhost:8500/v2/models/lstm_timeseries/ready
```

**ì •ìƒ ì‘ë‹µ**:
```json
{
  "models": [
    {
      "name": "lstm_timeseries",
      "version": "1",
      "state": "READY"
    }
  ]
}
```

#### 4.2.3 Metrics

```bash
# Prometheus í˜•ì‹ ë©”íŠ¸ë¦­
curl http://localhost:8502/metrics
```

**ì£¼ìš” ë©”íŠ¸ë¦­**:
```
# Inference count
nv_inference_count{model="lstm_timeseries",version="1"} 1234

# Inference execution time (microseconds)
nv_inference_exec_time_us{model="lstm_timeseries",version="1"} 125000

# Queue time
nv_inference_queue_time_us{model="lstm_timeseries",version="1"} 5000
```

### 4.3 Docker ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§

```bash
# ëª¨ë“  ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
docker stats

# íŠ¹ì • ì»¨í…Œì´ë„ˆë§Œ
docker stats triton-server analysis-worker-1
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
CONTAINER         CPU %   MEM USAGE / LIMIT    MEM %   NET I/O         BLOCK I/O
triton-server     15.2%   2.5GiB / 16GiB       15.6%   1.2MB / 800kB   10MB / 5MB
analysis-worker   5.8%    512MiB / 16GiB       3.2%    500kB / 300kB   2MB / 1MB
```

**ì£¼ì˜ì‚¬í•­**:
- Triton Server: GPU ë©”ëª¨ë¦¬ëŠ” ë³„ë„ í™•ì¸ í•„ìš”
- CPU > 80%: ê³¼ë¶€í•˜ ìƒíƒœ âš ï¸
- MEM > 90%: ë©”ëª¨ë¦¬ ë¶€ì¡± ìœ„í—˜ âŒ

### 4.4 GPU ëª¨ë‹ˆí„°ë§ (Triton Server)

```bash
# nvidia-smi ì‹¤í–‰
docker exec triton-server nvidia-smi

# 1ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
docker exec triton-server nvidia-smi -l 1
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 13.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  NVIDIA RTX 3090    On   | 00000000:01:00.0 Off |                  N/A |
| 30%   45C    P2    85W / 350W |   1850MiB / 24576MiB |     15%      Default |
+-------------------------------+----------------------+----------------------+
```

**ì •ìƒ ë²”ìœ„**:
- Temperature: < 80Â°C âœ…
- GPU Util: 10-50% (ì¶”ë¡  ì‘ì—… ì¤‘) âœ…
- Memory: < 20GB âœ…

---

## 5. ì¶”ë¡  ì‘ì—… ì‹¤í–‰

### 5.1 ìˆ˜ë™ ì¶”ë¡  (API)

#### 5.1.1 ë‹¨ì¼ ëª¨ë¸ ì¶”ë¡ 

```bash
curl -X POST http://localhost:8000/api/v1/inference/submit \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "lstm_timeseries",
    "data": [25.0, 26.1, 27.3, 28.5, 29.2, 30.1, 31.0, 32.4, 33.1, 34.5],
    "config": {
      "forecast_horizon": 5,
      "window_size": 10
    },
    "metadata": {
      "satellite_id": "SAT-001",
      "source": "manual"
    }
  }'
```

**ì‘ë‹µ**:
```json
{
  "job_id": "f47ac10b-58cc-4372-a567-0e02b2c3d479",
  "status": "pending",
  "message": "Inference job submitted to analysis server"
}
```

#### 5.1.2 ê²°ê³¼ ì¡°íšŒ

```bash
# job_idë¥¼ ë³€ìˆ˜ì— ì €ì¥
JOB_ID="f47ac10b-58cc-4372-a567-0e02b2c3d479"

# ìƒíƒœ í™•ì¸
curl http://localhost:8000/api/v1/inference/status/$JOB_ID

# ê²°ê³¼ ì¡°íšŒ (ì™„ë£Œ í›„)
curl http://localhost:8000/api/v1/inference/result/$JOB_ID | jq .
```

### 5.2 ìë™ ì¶”ë¡  (Kafka íŠ¸ë¦¬ê±°)

#### 5.2.1 ì‹œë®¬ë ˆì´í„° ì‹¤í–‰

```bash
cd tests
python3 satellite_simulator.py --kafka kafka:9092 --satellites 3 --interval 3 --duration 60
```

**íŒŒë¼ë¯¸í„°**:
- `--kafka`: Kafka ì£¼ì†Œ
- `--satellites`: ìœ„ì„± ìˆ˜ (1-10)
- `--interval`: ì „ì†¡ ê°„ê²© (ì´ˆ)
- `--duration`: ì‹¤í–‰ ì‹œê°„ (ì´ˆ)

**ì¶œë ¥ ì˜ˆì‹œ**:
```
================================================================================
ğŸ›°ï¸  ì¸ê³µìœ„ì„± í…”ë ˆë©”íŠ¸ë¦¬ ì‹œë®¬ë ˆì´í„°
================================================================================
ìœ„ì„± ê°œìˆ˜:     3
ì „ì†¡ ì£¼ê¸°:     3ì´ˆ
ì‹¤í–‰ ì‹œê°„:     60ì´ˆ
Kafka:        kafka:9092
================================================================================

[SAT-001] Satellite Simulator initialized
[SAT-002] Satellite Simulator initialized
[SAT-003] Satellite Simulator initialized

âœ… 3ê°œ ìœ„ì„± ì´ˆê¸°í™” ì™„ë£Œ

[0001] 12:00:00 | Elapsed: 0s / 60s
[0002] 12:00:03 | Elapsed: 3s / 60s
  [SAT-001] Image captured! (Total: 1)
```

#### 5.2.2 ìë™ íŠ¸ë¦¬ê±° ì¡°ê±´

ì‹œìŠ¤í…œì€ ë‹¤ìŒ ì¡°ê±´ì—ì„œ ìë™ìœ¼ë¡œ ì¶”ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:

1. **ë°°í„°ë¦¬ ë¶€ì¡±**: `battery_soc_percent < 30%`
2. **ì˜¨ë„ ì´ìƒ**: `obc_temp < -30Â°C` ë˜ëŠ” `> 50Â°C`
3. **ì¶”ì§„ì œ ì‘ë™**: `thruster_active = true`
4. **ì£¼ê¸°ì  ì²´í¬**: 10% í™•ë¥ 

#### 5.2.3 ìë™ ì¶”ë¡  í™•ì¸

```bash
# Kafka Inference Trigger ë¡œê·¸
docker logs kafka-inference-trigger --tail 50

# Analysis Worker ë¡œê·¸
docker logs analysis-worker-1 --tail 50
```

**ì •ìƒ ë¡œê·¸ ì˜ˆì‹œ**:
```
2025-10-30 12:34:56 - Low battery detected: 28%
2025-10-30 12:34:56 - Submitted eps inference for SAT-001: task-id-123
2025-10-30 12:34:56 - Submitted thermal inference for SAT-001: task-id-124
2025-10-30 12:34:56 - Submitted aocs inference for SAT-001: task-id-125
2025-10-30 12:34:56 - Submitted comm inference for SAT-001: task-id-126
2025-10-30 12:34:56 - Submitted 4 subsystem inferences for SAT-001 (job: kafka-SAT-001-1761802496)
```

### 5.3 ë°°ì¹˜ ì¶”ë¡ 

#### 5.3.1 Python ìŠ¤í¬ë¦½íŠ¸

```python
import requests
import time

# 10ê°œ ì‘ì—… ì œì¶œ
job_ids = []
for i in range(10):
    response = requests.post(
        'http://localhost:8000/api/v1/inference/submit',
        json={
            'model_name': 'lstm_timeseries',
            'data': [25.0 + i * 0.1] * 10,
            'config': {'forecast_horizon': 5}
        }
    )
    job_id = response.json()['job_id']
    job_ids.append(job_id)
    print(f'Submitted job {i+1}/10: {job_id}')
    time.sleep(0.1)

# ê²°ê³¼ ëŒ€ê¸°
print('\nWaiting for results...')
time.sleep(5)

# ê²°ê³¼ ì¡°íšŒ
for job_id in job_ids:
    result = requests.get(f'http://localhost:8000/api/v1/inference/result/{job_id}')
    if result.status_code == 200:
        print(f'{job_id}: {result.json()["status"]}')
```

---

## 6. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 6.1 ì¼ë°˜ì ì¸ ë¬¸ì œ

#### 6.1.1 Kafka ì—°ê²° ì‹¤íŒ¨

**ì¦ìƒ**:
```
Failed to resolve 'kafka:9092': Temporary failure in name resolution
```

**ì›ì¸**: Kafkaê°€ ì•„ì§ ì‹œì‘ ì¤‘ì´ê±°ë‚˜ ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ

**í•´ê²°**:
```bash
# Kafka ìƒíƒœ í™•ì¸
docker compose ps kafka

# Kafka ì¬ì‹œì‘
docker compose restart kafka

# 30ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
```

#### 6.1.2 RabbitMQ ì—°ê²° ì‹¤íŒ¨

**ì¦ìƒ**:
```
[ERROR] Consumer error: Connection refused
```

**í•´ê²°**:
```bash
# RabbitMQ ìƒíƒœ í™•ì¸
docker compose ps rabbitmq

# Health check
docker exec rabbitmq rabbitmq-diagnostics ping

# ì¬ì‹œì‘
docker compose restart rabbitmq
```

#### 6.1.3 PostgreSQL ì—°ê²° ì‹¤íŒ¨

**ì¦ìƒ**:
```
psycopg2.OperationalError: could not connect to server
```

**í•´ê²°**:
```bash
# PostgreSQL ìƒíƒœ
docker compose ps postgres

# ë¡œê·¸ í™•ì¸
docker logs postgres --tail 50

# ì¬ì‹œì‘
docker compose restart postgres
```

#### 6.1.4 Triton Server ì‹œì‘ ì‹¤íŒ¨

**ì¦ìƒ**:
```
triton-server    Exited (1)
```

**ì›ì¸**: GPU ë¬¸ì œ, ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨

**í•´ê²°**:
```bash
# ë¡œê·¸ í™•ì¸
docker logs triton-server

# GPU í™•ì¸
nvidia-smi

# ëª¨ë¸ ë””ë ‰í† ë¦¬ í™•ì¸
ls -la model_repository/

# ì¬ì‹œì‘
docker compose restart triton-server
```

### 6.2 ì„±ëŠ¥ ë¬¸ì œ

#### 6.2.1 Celery Task ì§€ì—°

**ì¦ìƒ**: Flowerì—ì„œ Taskê°€ PENDING ìƒíƒœë¡œ ëŒ€ê¸°

**ì§„ë‹¨**:
```bash
# Worker ìƒíƒœ í™•ì¸
docker exec analysis-worker-1 celery -A tasks inspect active

# RabbitMQ í ìƒíƒœ
docker exec rabbitmq rabbitmqctl list_queues
```

**í•´ê²°**:
1. **Worker ìˆ˜ ì¦ê°€**:
   ```bash
   docker compose up -d --scale analysis-worker-1=3
   ```

2. **Concurrency ì¦ê°€** (`docker-compose.yml`):
   ```yaml
   command: celery -A tasks worker --loglevel=info --concurrency=4
   ```

3. **Worker ì¬ì‹œì‘**:
   ```bash
   docker compose restart analysis-worker-1
   ```

#### 6.2.2 Kafka Consumer Lag

**ì¦ìƒ**: Consumer lag > 1000

**ì§„ë‹¨**:
```bash
docker exec kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe \
  --group analysis-inference-group
```

**í•´ê²°**:
1. **Partition ìˆ˜ ì¦ê°€**:
   ```bash
   docker exec kafka kafka-topics \
     --bootstrap-server localhost:9092 \
     --alter \
     --topic satellite-telemetry \
     --partitions 4
   ```

2. **Consumer ìˆ˜ ì¦ê°€** (Kafka Inference Trigger):
   ```yaml
   # docker-compose.yml
   kafka-inference-trigger:
     deploy:
       replicas: 2
   ```

### 6.3 ë°ì´í„° ë¬¸ì œ

#### 6.3.1 ì¤‘ë³µ Job ID

**ì¦ìƒ**:
```
duplicate key value violates unique constraint "inference_jobs_pkey"
```

**í•´ê²°**: ì´ë¯¸ ìˆ˜ì •ë¨ (ON CONFLICT ì‚¬ìš©)

í™•ì¸:
```sql
SELECT job_id, COUNT(*) FROM inference_jobs GROUP BY job_id HAVING COUNT(*) > 1;
```

#### 6.3.2 JSON ì§ë ¬í™” ì˜¤ë¥˜

**ì¦ìƒ**:
```
Object of type bool_ is not JSON serializable
```

**í•´ê²°**: ì´ë¯¸ ìˆ˜ì •ë¨ (numpy íƒ€ì… ë³€í™˜)

---

## 7. ì„±ëŠ¥ íŠœë‹

### 7.1 Celery Worker ìµœì í™”

```yaml
# docker-compose.yml
analysis-worker-1:
  command: celery -A tasks worker \
    --loglevel=info \
    --concurrency=4 \
    --max-tasks-per-child=100 \
    --prefetch-multiplier=2
```

**íŒŒë¼ë¯¸í„°**:
- `--concurrency`: ë™ì‹œ ì²˜ë¦¬ ì‘ì—… ìˆ˜ (CPU ì½”ì–´ ìˆ˜ì™€ ë™ì¼ ê¶Œì¥)
- `--max-tasks-per-child`: Worker ì¬ì‹œì‘ ì£¼ê¸° (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
- `--prefetch-multiplier`: Prefetch ì‘ì—… ìˆ˜ ë°°ìœ¨

### 7.2 PostgreSQL ìµœì í™”

#### 7.2.1 ì¸ë±ìŠ¤ í™•ì¸

```sql
SELECT schemaname, tablename, indexname FROM pg_indexes
WHERE tablename IN ('inference_jobs', 'subsystem_inferences');
```

#### 7.2.2 VACUUM

```sql
-- í…Œì´ë¸” ì •ë¦¬ (ì‚­ì œëœ í–‰ ì •ë¦¬)
VACUUM ANALYZE inference_jobs;
VACUUM ANALYZE subsystem_inferences;
```

### 7.3 Triton Server ìµœì í™”

**Dynamic Batching ì„¤ì •** (`model_repository/lstm_timeseries/config.pbtxt`):
```protobuf
dynamic_batching {
  preferred_batch_size: [4, 8]
  max_queue_delay_microseconds: 100000
}
```

### 7.4 ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# monitor.sh - ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½

echo "=== System Status ==="
echo ""

echo "Services:"
docker compose ps --format "table {{.Service}}\t{{.Status}}"
echo ""

echo "RabbitMQ Queue:"
docker exec rabbitmq rabbitmqctl list_queues | grep inference
echo ""

echo "Kafka Lag:"
docker exec kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe \
  --group analysis-inference-group | grep satellite-telemetry
echo ""

echo "PostgreSQL Stats:"
docker exec postgres psql -U admin -d orders_db -c \
  "SELECT COUNT(*) as total,
          COUNT(CASE WHEN status='completed' THEN 1 END) as completed,
          COUNT(CASE WHEN status='processing' THEN 1 END) as processing
   FROM inference_jobs
   WHERE created_at > NOW() - INTERVAL '1 hour';"
echo ""

echo "GPU Status:"
docker exec triton-server nvidia-smi --query-gpu=utilization.gpu,utilization.memory,temperature.gpu --format=csv,noheader
```

**ì‚¬ìš©**:
```bash
chmod +x monitor.sh
./monitor.sh
```

---

## ë¶€ë¡

### A. í™˜ê²½ ë³€ìˆ˜

ì£¼ìš” í™˜ê²½ ë³€ìˆ˜ ëª©ë¡ (`.env` ë˜ëŠ” `docker-compose.yml`):

```bash
# Kafka
KAFKA_CLUSTER_ID=<auto-generated>
KAFKA_BOOTSTRAP_SERVERS=kafka:9092

# RabbitMQ
CELERY_BROKER_URL=amqp://guest:guest@rabbitmq:5672//
CELERY_RESULT_BACKEND=rpc://

# PostgreSQL
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=admin
POSTGRES_PASSWORD=admin123
POSTGRES_DB=orders_db

# Triton
TRITON_SERVER_URL=triton-server:8001

# VictoriaMetrics
VICTORIA_METRICS_URL=http://victoria-metrics:8428
```

### B. í¬íŠ¸ ëª©ë¡

| í¬íŠ¸ | ì„œë¹„ìŠ¤ | ì„¤ëª… |
|------|--------|------|
| 80 | Nginx | ì›¹ í”„ë¡ íŠ¸ì—”ë“œ |
| 8000 | Operation Server | API |
| 8080 | Kafka UI | Kafka ëª¨ë‹ˆí„°ë§ |
| 8428 | VictoriaMetrics | ì‹œê³„ì—´ DB |
| 8500 | Triton HTTP | Triton HTTP API |
| 8501 | Triton gRPC | Triton gRPC API |
| 8502 | Triton Metrics | Triton ë©”íŠ¸ë¦­ |
| 9092 | Kafka | ë©”ì‹œì§€ ë¸Œë¡œì»¤ |
| 5432 | PostgreSQL | ë°ì´í„°ë² ì´ìŠ¤ |
| 5555 | Flower | Celery ëª¨ë‹ˆí„° |
| 5672 | RabbitMQ AMQP | ì‘ì—… í |
| 15672 | RabbitMQ Management | í ê´€ë¦¬ UI |
| 9200 | Elasticsearch | ê²€ìƒ‰ ì—”ì§„ |

### C. ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜

ì»¨í…Œì´ë„ˆ ë¡œê·¸ëŠ” Dockerì—ì„œ ê´€ë¦¬:
```bash
docker logs <container_name>
```

ì˜êµ¬ ë¡œê·¸ ì €ì¥:
```bash
docker logs <container_name> > /path/to/logfile.log 2>&1
```

### D. ìœ ìš©í•œ ëª…ë ¹ì–´ ëª¨ìŒ

```bash
# ì „ì²´ ì¬ì‹œì‘ (ë°ì´í„° ìœ ì§€)
docker compose restart

# íŠ¹ì • ì„œë¹„ìŠ¤ë§Œ ì¬ë¹Œë“œ
docker compose build --no-cache operation-server
docker compose up -d operation-server

# ë¡œê·¸ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (ì—¬ëŸ¬ ì„œë¹„ìŠ¤)
docker compose logs -f operation-server analysis-worker-1 kafka-inference-trigger

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
docker system df

# ì •ë¦¬ (ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€, ì»¨í…Œì´ë„ˆ ì‚­ì œ)
docker system prune -a

# Volume ëª©ë¡
docker volume ls

# íŠ¹ì • Volume ì‚­ì œ
docker volume rm satellite_postgres_data
```
